{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "390dfab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB version: 1.7.6\n",
      "negative trends\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from numpy import nan\n",
    "import xgboost as xgb\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#print(cwd)\n",
    "\n",
    "# DRAC directory\n",
    "#os.chdir(\"/home/georod/projects/def-mfortin/georod/scripts/github/forc_trends/models/xgboost\")\n",
    "# Win directory\n",
    "os.chdir(r'C:\\Users\\Peter R\\github\\forc_stpa\\models\\xgboost\\exploratory')\n",
    "\n",
    "\n",
    "print(\"XGB version:\", xgb.__version__)\n",
    "print(\"negative trends\")\n",
    "\n",
    "\n",
    "# Windows\n",
    "#df1 = pd.read_csv(r'.\\data\\df2_trends_p1_vars_greening_v5.csv', skipinitialspace=True)\n",
    "df1 = pd.read_csv(r'.\\data\\df2_trends_p1_vars_browning_v5.csv', skipinitialspace=True)\n",
    "# DRAC\n",
    "#df1 = pd.read_csv(r'./data/forest_evi_breaks_positive_v2.csv', skipinitialspace=True)\n",
    "#df1.head()\n",
    "\n",
    "\n",
    "df11 = pd.get_dummies(df1, columns=['for_pro'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c866a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF columns + protected\n",
    "#cols2 = ['delta_dd5_wt_lag3', 'delta_cmi_sm_lag2', 'delta_cmi_sm_lag1', 'delta_for_age', 'delta_for_con','for_pro_0']\n",
    "\n",
    "cols2 = ['delta_cmi_sm_lag3',  'delta_dd5_wt_lag3',  'delta_cmi_sm_lag2',  'delta_dd5_wt_lag2',  'delta_cmi_sm_lag1',  \n",
    "         'delta_dd5_wt_lag1',  'delta_for_age',  'delta_for_con',  'delta_cmi_sm',  'delta_dd5_wt',  'deltap_for_age',  \n",
    "         'deltap_for_con',  'cmi_sm_rel30_reg',  'dd5_wt_rel30_reg',  'cmi_sm_rel30p_reg',  'dd5_wt_rel30p_reg',  \n",
    "         'cmi_sm_rel30',  'dd5_wt_rel30']\n",
    "\n",
    "df0 = df11.loc[(df11['for_age_2003'] >= 0) & (df11['elev'] > 0)]\n",
    "dfall = [df0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3f74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pix     year  for_age_2003  for_con_2003          elev  \\\n",
      "count   10127.000000  10127.0  10127.000000  10127.000000  10127.000000   \n",
      "mean   237167.221191   2003.0     90.859603     34.461823    375.535490   \n",
      "std    138216.246576      0.0     15.503036     19.293782     85.656141   \n",
      "min       613.000000   2003.0     40.004000      2.675000    121.629000   \n",
      "25%    124192.500000   2003.0     79.762500     18.704000    307.491000   \n",
      "50%    224723.000000   2003.0     88.362000     29.259000    388.362000   \n",
      "75%    356393.000000   2003.0    100.386000     48.282000    446.374000   \n",
      "max    493323.000000   2003.0    170.139000     88.409000    543.641000   \n",
      "\n",
      "       p1_trend  p1_trend_slope  trend_20yrs  delta_for_age_lag3  \\\n",
      "count   10127.0    10127.000000  6483.000000                 0.0   \n",
      "mean        2.0       -4.937435     1.550979                 NaN   \n",
      "std         0.0        1.789729     1.448057                 NaN   \n",
      "min         2.0      -19.674000     1.000000                 NaN   \n",
      "25%         2.0       -5.456500     1.000000                 NaN   \n",
      "50%         2.0       -4.471000     1.000000                 NaN   \n",
      "75%         2.0       -3.845000     1.000000                 NaN   \n",
      "max         2.0       -2.369000     8.000000                 NaN   \n",
      "\n",
      "       delta_for_con_lag3  ...  min_mat_rel30_reg  max_mat_rel30_reg  \\\n",
      "count                 0.0  ...       10127.000000       10127.000000   \n",
      "mean                  NaN  ...           0.936312           1.422334   \n",
      "std                   NaN  ...           0.105134           0.104802   \n",
      "min                   NaN  ...           0.697000           1.187000   \n",
      "25%                   NaN  ...           0.851000           1.345000   \n",
      "50%                   NaN  ...           0.923000           1.409000   \n",
      "75%                   NaN  ...           1.005000           1.492000   \n",
      "max                   NaN  ...           1.266000           1.767000   \n",
      "\n",
      "       cmi_sm_rel30  dd5_wt_rel30  cmi_sm_rel30_reg  dd5_wt_rel30_reg  \\\n",
      "count  10127.000000  10127.000000      10127.000000      10127.000000   \n",
      "mean      -1.570829      2.312304         -1.949902          2.282816   \n",
      "std        0.252244      0.517372          1.243043          0.952148   \n",
      "min       -1.975607      1.344000         -5.722000          0.850000   \n",
      "25%       -1.781683      2.000000         -2.904000          1.363000   \n",
      "50%       -1.646432      2.249000         -1.774000          2.420000   \n",
      "75%       -1.401684      2.600000         -0.934000          2.948000   \n",
      "max       -0.818475      4.004000          1.374000          5.254000   \n",
      "\n",
      "       cmi_sm_rel30p_reg  dd5_wt_rel30p_reg     for_pro_0     for_pro_1  \n",
      "count       10127.000000       10127.000000  10127.000000  10127.000000  \n",
      "mean           89.445073          60.875076      0.896218      0.103782  \n",
      "std            57.020306          25.390651      0.304993      0.304993  \n",
      "min           -63.028000          22.667000      0.000000      0.000000  \n",
      "25%            42.844000          36.346500      1.000000      0.000000  \n",
      "50%            81.376000          64.533000      1.000000      0.000000  \n",
      "75%           133.211000          78.613000      1.000000      0.000000  \n",
      "max           262.477000         140.107000      1.000000      1.000000  \n",
      "\n",
      "[8 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfall[0].describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e84d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(len(dfall)):\n",
    "    #list_of_vars = [[cols1], [cols2], [cols3]]\n",
    "    list_of_vars = [[cols2]]\n",
    "    for index, list in enumerate(list_of_vars):\n",
    "        for x in list:\n",
    "            #print(x)\n",
    "            X1 = dfall[z][x]\n",
    "            #print(X1.describe())\n",
    "            y1 = dfall[z].iloc[:,6].abs()\n",
    "            seed = 7 # random seed to help with replication\n",
    "            testsize1 = 0.33 # percent of records to test after training\n",
    "            x1_train, x1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=testsize1, random_state=seed) # Split data set. Note the 'stratify' option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc791c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune parameters using GridSearchCV (for exhaustive searches) or RandomizedSearchCV (faster)\n",
    "# max_depth is tree complexity in Elith et al. 2008\n",
    "# n_estimators=100 is the number of trees. Elith et al. 2008 say this should be 1000 at least\n",
    "# Elith et al. 2008 suggests low learning rate\n",
    "\n",
    "params_xgboost = {\n",
    " #\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    " \"learning_rate\"    : [ 0.01, 0.05, 0.10, 0.15, 0.20, 0.25],\n",
    " #\"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8],\n",
    " #\"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " #\"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"gamma\"            : [ 0.0, 0.05, 0.1, 0.2, 0.3, 0.4],\n",
    " #\"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7],\n",
    " #'n_estimators'     : [5, 10, 15, 20, 25, 30, 35],\n",
    "'n_estimators'     : [300],\n",
    " 'objective': ['reg:squarederror'],\n",
    "#'early_stopping_rounds': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919c5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.15, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "model_m2b = XGBRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = model_m2b, \n",
    "                      param_distributions = params_xgboost, \n",
    "                      n_iter = 100, \n",
    "                      cv = 5, \n",
    "                      verbose=10, \n",
    "                      random_state=42,\n",
    "                      scoring = 'neg_mean_squared_error', \n",
    "                      n_jobs = -1)\n",
    "\n",
    "#params glare proba\n",
    "random_search.fit(x1_train, y1_train)\n",
    "\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80cee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(random_search.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4db593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters from best model used in Chapter 3\n",
    "#Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "             colsample_bylevel=None, colsample_bynode=None,\n",
    "             colsample_bytree=None, early_stopping_rounds=None,\n",
    "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "             gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "             interaction_constraints=None, learning_rate=0.15, max_bin=None,\n",
    "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
    "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
    "             predictor=None, random_state=None, ...)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
